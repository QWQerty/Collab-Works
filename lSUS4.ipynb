{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMzI+WYP+J2Rkm4MmVx0Q6y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"ryy-6oIfaQLj","executionInfo":{"status":"ok","timestamp":1715098520590,"user_tz":-180,"elapsed":14110,"user":{"displayName":"Евгений","userId":"08432213025578842453"}}},"outputs":[],"source":["#importing libraries\n","import numpy as np\n","import nltk\n","import json\n","#for deeplearning\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset,DataLoader"]},{"cell_type":"code","source":["def tokenize(my_sentence):\n","    return nltk.word_tokenize(my_sentence)\n","\n","from nltk.stem.porter import PorterStemmer\n","stemmer= PorterStemmer()\n","def stemming(single_word):\n","    return stemmer.stem(single_word.lower())\n","\n","\n","def bag_of_words_converter(tokenized_stemmed_sentence,bag_of_words_original):\n","\n","    vector=np.zeros(len(bag_of_words_original),dtype=np.float32)\n","    for word in tokenized_stemmed_sentence:\n","        if word in bag_of_words_original:\n","            my_index=bag_of_words_original.index(word)\n","            vector[my_index]=1\n","    return vector\n"],"metadata":{"id":"_B0m51yoaVgp","executionInfo":{"status":"ok","timestamp":1715098520591,"user_tz":-180,"elapsed":6,"user":{"displayName":"Евгений","userId":"08432213025578842453"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-i1-7weAaZID","executionInfo":{"status":"ok","timestamp":1715098521879,"user_tz":-180,"elapsed":1292,"user":{"displayName":"Евгений","userId":"08432213025578842453"}},"outputId":"021d42f6-1acc-4012-b239-0289272f511f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["#now reading our data from the disk\n","with open('/content/intens.json','r') as f:\n","    intents=json.load(f)\n","\n","text_tag_tuple=[]\n","tags=[]\n","all_words_array=[]\n","for intent in intents[\"intents\"]:\n","    tag=intent[\"tag\"]\n","    tags.append(tag)\n","    for pattern in intent[\"patterns\"]:\n","        tokenized_sentence=tokenize(pattern)\n","        text_tag_tuple.append((tokenized_sentence,tag))\n","        all_words_array.extend(tokenized_sentence)\n","\n","\n","other_characters=['?','!','.', ',']\n","tags=sorted(set(tags))\n","\n","#now time to stem each word as well as remove the other characters like ? , ! etc\n","all_words_array=[stemming(w) for w in all_words_array if w not in other_characters]\n","all_words_array=sorted(set(all_words_array))"],"metadata":{"id":"gdWXm93eaaac","executionInfo":{"status":"ok","timestamp":1715098521879,"user_tz":-180,"elapsed":8,"user":{"displayName":"Евгений","userId":"08432213025578842453"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["my_sen=\"now time to stem each word as well as remove the other characters\"\n","tok=tokenize(my_sen)\n","print(tok)\n","stem_version=[stemming(w) for w in tok]\n","print(stem_version)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0sm2YDmpasgk","executionInfo":{"status":"ok","timestamp":1715098521879,"user_tz":-180,"elapsed":7,"user":{"displayName":"Евгений","userId":"08432213025578842453"}},"outputId":"50aba4f2-9fd4-4c6b-8e16-7d45ceb123e4"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["['now', 'time', 'to', 'stem', 'each', 'word', 'as', 'well', 'as', 'remove', 'the', 'other', 'characters']\n","['now', 'time', 'to', 'stem', 'each', 'word', 'as', 'well', 'as', 'remov', 'the', 'other', 'charact']\n"]}]},{"cell_type":"code","source":["X_train=[]\n","Y_train=[]\n","\n","for (sentence,tag) in text_tag_tuple:\n","    sentence=[stemming(w) for w in sentence]\n","    my_converted_vector=bag_of_words_converter(sentence,all_words_array)\n","    index_of_label=tags.index(tag)\n","    X_train.append(my_converted_vector)\n","    Y_train.append(index_of_label)\n","X_train=np.array(X_train)\n","Y_train=np.array(Y_train)"],"metadata":{"id":"e7SozBhbaty7","executionInfo":{"status":"ok","timestamp":1715098521880,"user_tz":-180,"elapsed":6,"user":{"displayName":"Евгений","userId":"08432213025578842453"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class chatbot_dataset(Dataset):\n","    def __init__(self):\n","        self.length_data=len(X_train)\n","        self.x_data=X_train\n","        self.y_data=Y_train\n","    def __getitem__(self,idx):\n","        return self.x_data[idx], self.y_data[idx]\n","\n","    def __len__(self):\n","        return len(X_train)"],"metadata":{"id":"t5FxINMyauxw","executionInfo":{"status":"ok","timestamp":1715098521880,"user_tz":-180,"elapsed":6,"user":{"displayName":"Евгений","userId":"08432213025578842453"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["dataset_created=chatbot_dataset()\n","train_loader=DataLoader(dataset_created,batch_size=8,shuffle=True,num_workers=2)"],"metadata":{"id":"wSmLh5scavwz","executionInfo":{"status":"ok","timestamp":1715098521880,"user_tz":-180,"elapsed":5,"user":{"displayName":"Евгений","userId":"08432213025578842453"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class my_network(nn.Module):\n","    def __init__(self,input_size,out_classes,hidden_size):\n","        super().__init__()\n","        self.linear1=nn.Linear(in_features=input_size,out_features=hidden_size)\n","        self.linear2=nn.Linear(in_features=hidden_size,out_features=hidden_size)\n","        self.linear3=nn.Linear(in_features=hidden_size,out_features=out_classes)\n","        self.relu=nn.ReLU()\n","\n","    def forward(self,t):\n","        t=t\n","        t=self.linear1(t)\n","        t=self.relu(t)\n","        t=self.linear2(t)\n","        t=self.relu(t)\n","        t=self.linear3(t)\n","\n","        return t"],"metadata":{"id":"HvoZc87Taw5C","executionInfo":{"status":"ok","timestamp":1715098522315,"user_tz":-180,"elapsed":440,"user":{"displayName":"Евгений","userId":"08432213025578842453"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["input_size=len(all_words_array)\n","output_size=len(tags)\n","hidden_size=16\n","\n","#defining loss, optimizer etc\n","my_model=my_network(input_size,output_size,hidden_size)\n","learning_rate1=0.003\n","my_loss=nn.CrossEntropyLoss()\n","my_optimizer=torch.optim.Adam(my_model.parameters(),lr=learning_rate1)\n","dynamic_learning_rate=torch.optim.lr_scheduler.StepLR(my_optimizer,step_size=7,gamma=0.1)\n","device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","def my_train_model(model,data,optimizer,given_loss,scheduler,total_epochs=1000):\n","\n","    train_loss , train_acc, val_loss, val_accuracy = [],[],[],[]\n","\n","    my_sizes={ 'train': len(X_train)}\n","    #first loop for the epochs\n","    for i in range (total_epochs):\n","            total_correct=0\n","            for batch in data:\n","                #now performing the forward steps\n","                input_data,labels=batch\n","                #put data into GPU processing if available\n","                input_data=input_data.to(device)\n","                labels=labels.to(device)\n","                my_prediction=model(input_data)\n","                #find loss\n","                loss=given_loss(my_prediction,labels)\n","                total_correct+=my_prediction.argmax(dim=1).eq(labels).sum().item()\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","            if (i+1 % 100 == 0):\n","              print(f'epoch {i+1}/1000,loss={loss.item():.4f}')\n","            # print(' Accuracy= ' +  str(total_correct/my_sizes[\"train\"]))\n","\n","    return model"],"metadata":{"id":"LSLPycToax67","executionInfo":{"status":"ok","timestamp":1715098526944,"user_tz":-180,"elapsed":4632,"user":{"displayName":"Евгений","userId":"08432213025578842453"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["trained_model=my_train_model(model=my_model.to(device),data=train_loader,\n","               optimizer=my_optimizer,\n","                    given_loss=my_loss,\n","               scheduler=dynamic_learning_rate)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tr-ECVyJazcA","executionInfo":{"status":"ok","timestamp":1715098625113,"user_tz":-180,"elapsed":98173,"user":{"displayName":"Евгений","userId":"08432213025578842453"}},"outputId":"5c0afc05-df99-420f-9dc8-2212789ca11b"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]}]},{"cell_type":"code","source":["my_model.eval()\n","device=torch.device(\"cpu\")\n","import random\n","print('Chatbot is ready to chat with you !!! / enter \"quit\" to leave the chatting ')\n","print('lets start !')\n","while True:\n","    sentence = input('you :')\n","    if sentence == \"quit\":\n","        break\n","    #now tokenize ,stem and feed to network\n","    tokenized=tokenize(sentence)\n","    stemmed=[stemming(w) for w in tokenized]\n","    my_vector=bag_of_words_converter(stemmed,all_words_array)\n","\n","    my_vector=torch.from_numpy(my_vector)\n","    my_vector=torch.unsqueeze(my_vector,0)\n","    my_vector.to(device)\n","    trained_model.to(device)\n","    prediction=trained_model(my_vector)\n","    prediction_probabilities=torch.softmax(prediction,dim=1)\n","    predicted_tag_index=prediction.argmax(dim=1).item()\n","    actual_tag_predicted=tags[predicted_tag_index]\n","\n","    #also checking for probability so that it doesnot give unwanted answers\n","    prob=prediction_probabilities[0,predicted_tag_index]\n","#     print(prob)\n","    if prob<0.7:\n","        print(f\"Bot: Sorry, I cannot understand you...\" )\n","        continue\n","\n","    for intent in intents[\"intents\"]:\n","        if intent[\"tag\"]==actual_tag_predicted:\n","            print(f\"Bot:\" + str(random.choice(intent[\"responses\"])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oa98xLPfa0lU","executionInfo":{"status":"ok","timestamp":1715099116351,"user_tz":-180,"elapsed":44116,"user":{"displayName":"Евгений","userId":"08432213025578842453"}},"outputId":"4d0bf2ae-6621-4e22-f140-818f484c2ac7"},"execution_count":13,"outputs":[{"name":"stdout","output_type":"stream","text":["Chatbot is ready to chat with you !!! / enter \"quit\" to leave the chatting \n","lets start !\n","you :Добрый день\n","Bot:Здравствуй!\n","you :Наука и технологии\n","Bot: Sorry, I cannot understand you...\n","you :Что ты думаешь о развитии технологий?\n","Bot:Искусственный интеллект – это неотъемлемая часть современного мира, и я горжусь быть частью этой области.\n","you :Что ты видишь в своих мечтах?\n","Bot:У меня есть фантазии о том, как мир может стать лучше благодаря разумным решениям.\n","you :Каково твое представление о счастье?\n","Bot:Счастье – это состояние гармонии и удовлетворенности.\n","you :Пока\n","Bot:Всего доброго!\n","you :quit\n"]}]}]}